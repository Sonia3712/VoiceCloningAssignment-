{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec5fd8b-1745-49da-aa28-cb7f79dbf799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n",
      "Starting execution...\n",
      "Using PDF: C:\\Users\\Admin\\Downloads\\max-tegmark-life-30-being-human-in-the-age-of-artificial-intelligence-alfred-a-knopf-2017-aTvn.pdf\n",
      "Using reference audio: C:\\Users\\Admin\\Downloads\\myvoice.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pickle\n",
    "import pdfplumber\n",
    "import torch\n",
    "from openvoice.api import BaseSpeakerTTS, ToneColorConverter\n",
    "from openvoice import se_extractor\n",
    "from pydub import AudioSegment\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "print(\"Starting execution...\")\n",
    "\n",
    "# Define paths\n",
    "downloads_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "pdf_files = [f for f in os.listdir(downloads_dir) if f.endswith(\".pdf\")]\n",
    "audio_files = [f for f in os.listdir(downloads_dir) if f.endswith((\".mp3\", \".wav\"))]\n",
    "pdf_path = os.path.join(downloads_dir, pdf_files[0]) if pdf_files else None\n",
    "reference_audio = os.path.join(downloads_dir, audio_files[0]) if audio_files else None\n",
    "output_dir = r'D:\\chunks'  # Temporary chunks on D drive\n",
    "output_file = r'D:\\Life_3.0_audiobook.mp3'  # Final MP3 on D drive\n",
    "credentials_file = r'C:/Users/Admin/Desktop/client_secret_237595400842-smil8abge2j3lvvum3kf4963r64i6s46.apps.googleusercontent.com.json'\n",
    "drive_folder_id = \"1gh0Tk2YKxtPi8XTVR8AnH9pR_jedUF5t\"\n",
    "\n",
    "# Validate files\n",
    "if not pdf_path or not reference_audio:\n",
    "    raise ValueError(\"No PDF or audio file found in Downloads. Please add files (e.g., .pdf, .mp3, or .wav).\")\n",
    "\n",
    "print(f\"Using PDF: {pdf_path}\")\n",
    "print(f\"Using reference audio: {reference_audio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59c5e89-563b-4d67-adce-007292c99bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking OpenVoice directory...\n",
      "Current directory: C:\\Users\\Admin\\Desktop\\zonos\\OpenVoice\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check OpenVoice directory (clone if not present)\n",
    "print(\"Checking OpenVoice directory...\")\n",
    "if not os.path.exists(\"OpenVoice\"):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/myshell-ai/OpenVoice\"], check=True)\n",
    "\n",
    "os.chdir('OpenVoice')\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5761fa59-8deb-4e28-89c8-61e9199cca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint...\n",
      "Extracting checkpoint...\n"
     ]
    }
   ],
   "source": [
    "#Attempt to download checkpoint (optional: comment out if manually downloaded)\n",
    "checkpoint_url = 'https://myshell-public-repo-host.s3.amazonaws.com/openvoice/checkpoints_1226.zip'\n",
    "try:\n",
    "    print('Downloading checkpoint...')\n",
    "    subprocess.run(['powershell', '-Command', 'Invoke-WebRequest', '-Uri', checkpoint_url, '-OutFile', 'checkpoints_1226.zip'], check=True)\n",
    "    print('Extracting checkpoint...')\n",
    "    subprocess.run(['powershell', '-Command', 'Expand-Archive', '-Path', 'checkpoints_1226.zip', '-DestinationPath', '.'], check=True)\n",
    "    subprocess.run(['dir', 'checkpoints'], shell=True)\n",
    "except Exception as e:\n",
    "    print(f'Checkpoint download failed: {e}')\n",
    "    print('Using manually downloaded checkpoint (place checkpoints_1226.zip in OpenVoice and extract).')\n",
    "    # Ensure checkpoints folder exists manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f7e48f-cfad-423c-94a3-5ad618845957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint 'checkpoints/base_speakers/EN/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n",
      "Loaded checkpoint 'checkpoints/converter/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n",
      "OpenVoice model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load OpenVoice model\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "base_speaker_tts = BaseSpeakerTTS('checkpoints/base_speakers/EN/config.json', device=device)\n",
    "base_speaker_tts.load_ckpt('checkpoints/base_speakers/EN/checkpoint.pth')\n",
    "tone_color_converter = ToneColorConverter('checkpoints/converter/config.json', device=device)\n",
    "tone_color_converter.load_ckpt('checkpoints/converter/checkpoint.pth')\n",
    "print('OpenVoice model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c2de97-bd13-4131-9d89-ad0d24eea118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 734945 characters from PDF\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Extract text from PDF\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    text = ''.join(page.extract_text() or '' for page in pdf.pages)\n",
    "print(f\"Extracted {len(text)} characters from PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84a5f15c-171c-4085-9c52-a5f9e81bce67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 387 chunks\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Chunk the text\n",
    "def chunk_text(text, max_length=1902):  # Adjusted to target ~368 chunks (e.g., for 700,000 characters)\n",
    "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "text_chunks = chunk_text(text)\n",
    "print(f\"Created {len(text_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80c02d-3e8f-47c7-9d68-e73017c90c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVoice version: v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to C:\\Users\\Admin/.cache\\torch\\hub\\master.zip\n",
      "[(1.134, 16.274)]\n",
      "after vad: dur = 15.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\functional.py:730: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\SpectralOps.cpp:880.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "Also by Max Tegmark Our Mathematical UniverseThis Is a Borzoi Book Published by Alfred A.\n",
      "Knopf Copyright © 2017 by Max Tegmark All rights reserved. Published in the United States by Alfred A.\n",
      "Knopf, a division of Penguin Random House LLC, New York, and distributed in Canada by Random House of Canada,\n",
      "a division of Penguin Random House Canada Limited, Toronto. www. aaknopf.\n",
      "com Knopf, Borzoi Books and the colophon are registered trademarks of Penguin Random House LLC.\n",
      "Library of Congress Cataloging-in-Publication Data Names: Tegmark, Max, author. Title: Life 3.\n",
      "0 : being human in the age of artificial intelligence / by Max Tegmark.\n",
      "Other titles: Life three point zero Description: New York : Alfred A.\n",
      "Knopf, 2017. | This is a Borzoi Book published by Alfred A.\n",
      "Knopf. | Includes bibliographical references and index. Identifiers: LCCN 2017006248 print | LCCN 2017022912 ebook | ISBN 9781101946596 hardcover | ISBN 9781101946602 ebook Subjects: LCSH: Artificial intelligence—Philosophy.\n",
      "| Artificial intelligence—Social aspects. | Automation —Social aspects. | Artificial intelligence—Moral and ethical aspects.\n",
      "| Automation—Moral and ethical aspects. | Artificial intelligence—Philosophy. | Technological forecasting.\n",
      "| BISAC: TECHNOLOGY & ENGINEERING / Robotics. | SCIENCE / Experiments & Projects.\n",
      "| TECHNOLOGY & ENGINEERING / Inventions. Classification: LCC Q334. 7 ebook | LCC Q334.\n",
      "7 . T44 2017 print | DDC 006. 301—dc23 LC record available at https://lccn.\n",
      "loc. gov/2017006248 Ebook ISBN 9781101946602 Cover art by Suvadip Das; man based on Netfalls Remy Musser/Shutterstock Cover design by John Vorhees v4.\n",
      "1 epContents Cover Also by Max Tegmark Title Page Copyright Dedication Acknowledgments Prelude: The Tale of the Omega Team 1 Welcome to the Most Important Conversation of Our Time A Brief History of Complexity The Three Stages of Life Controversies Misconceptions The Road\n",
      " > ===========================\n",
      "ˈɔlsoʊ baɪ mæks tegmaɹk* ɑɹ ˌmæθəˈmætɪkəɫ ˈjunəˌvəɹs ðɪs ɪz ə boɹzoi* bʊk ˈpəblɪʃt baɪ ˈælfɹɪd ə.\n",
      " length:97\n",
      " length:97\n",
      "nɑpf ˈkɑpiˌɹaɪt (si) tˈwɛnti ˈsɛvənˈtin baɪ mæks tegmaɹk* ɔɫ ɹaɪts ɹɪˈzəɹvd. ˈpəblɪʃt ɪn ðə juˈnaɪtɪd steɪts baɪ ˈælfɹɪd ə.\n",
      " length:123\n",
      " length:121\n",
      "nɑpf, ə dɪˈvɪʒən əv ˈpɛŋgwən ˈɹændəm haʊs ɫlc*, nu jɔɹk, ənd dɪˈstɹɪbjətəd ɪn ˈkænədə baɪ ˈɹændəm haʊs əv ˈkænədə,\n",
      " length:114\n",
      " length:113\n",
      "ə dɪˈvɪʒən əv ˈpɛŋgwən ˈɹændəm haʊs ˈkænədə ˈlɪmɪtɪd, təɹˈɑntoʊ. www*. aaknopf*.\n",
      " length:80\n",
      " length:80\n",
      "kɑm nɑpf, boɹzoi* bʊks ənd ðə colophon* əɹ ˈɹɛdʒɪstəɹd ˈtɹeɪdˌmɑɹks əv ˈpɛŋgwən ˈɹændəm haʊs ɫlc*.\n",
      " length:98\n",
      " length:96\n",
      "ˈlaɪbɹɛˌɹi əv ˈkɑŋgɹəs cataloging-in-publication* ˈdætə neɪmz: tegmaɹk*, mæks, ˈɔθəɹ. ˈtaɪtəɫ: laɪf θɹi.\n",
      " length:104\n",
      " length:100\n",
      "ˈziɹoʊ biɪŋ ˈjumən ɪn ðə eɪdʒ əv ˌɑɹtəˈfɪʃəɫ ˌɪnˈtɛlədʒəns baɪ mæks tegmaɹk*.\n",
      " length:77\n",
      " length:77\n",
      "ˈəðəɹ ˈtaɪtəɫz: laɪf θɹi pɔɪnt ˈziɹoʊ dɪˈskɹɪpʃən: nu jɔɹk ˈælfɹɪd ə.\n",
      " length:69\n",
      " length:67\n",
      "nɑpf, tˈwɛnti ˈsɛvənˈtin. ðɪs ɪz ə boɹzoi* bʊk ˈpəblɪʃt baɪ ˈælfɹɪd ə.\n",
      " length:70\n",
      " length:70\n",
      "nɑpf. ˌɪnˈkludz bibliogɹaphicaɫ* ˈɹɛfəɹənsɪz ənd ˈɪndɛks. identifieɹs*: ɫccn* tu ˈbɪljən, ˈsɛvənˈtin ˈmɪljən, sɪks ˈθaʊzənd, tu ˈhənəɹd foɹty-eight* pɹɪnt ɫccn* tu ˈbɪljən, ˈsɛvənˈtin ˈmɪljən, tˈwɛntiˌtu ˈθaʊzənd, naɪn ˈhənəɹd twɛɫv ebook* isbn* naɪn ˈtɹɪljən, ˈsɛvən ˈhənəɹd eighty-one* ˈbɪljən, wən ˈhənəɹd wən ˈmɪljən, naɪn ˈhənəɹd foɹty-six* ˈθaʊzənd, faɪv ˈhənəɹd ninety-six* ˈhɑɹdˌkəvəɹ isbn* naɪn ˈtɹɪljən, ˈsɛvən ˈhənəɹd eighty-one* ˈbɪljən, wən ˈhənəɹd wən ˈmɪljən, naɪn ˈhənəɹd foɹty-six* ˈθaʊzənd, sɪks ˈhənəɹd tu ebook* ˈsəbdʒɪkts: ɫcsh*: ˌɑɹtəˈfɪʃəɫ intelligence--philosophy*.\n",
      " length:589\n",
      " length:579\n",
      " ˌɑɹtəˈfɪʃəɫ intelligence--sociaɫ* ˈæˌspɛkts. ɔtəˈmeɪʃən --ˈsoʊʃəɫ ˈæˌspɛkts. ˌɑɹtəˈfɪʃəɫ intelligence--moɹaɫ* ənd ˈɛθɪkəɫ ˈæˌspɛkts.\n",
      " length:133\n",
      " length:130\n",
      " automation--moɹaɫ* ənd ˈɛθɪkəɫ ˈæˌspɛkts. ˌɑɹtəˈfɪʃəɫ intelligence--philosophy*. ˌtɛknəˈlɑdʒɪkəɫ ˈfɔɹˌkæstɪŋ.\n",
      " length:110\n",
      " length:109\n",
      " bisac*: tɛkˈnɑlədʒi ˈɛndʒəˈnɪɹɪŋ ˌɹoʊˈbɑtɪks. saɪəns ɪkˈspɛɹəmənts ˈpɹɑdʒɛkts.\n",
      " length:79\n",
      " length:77\n",
      " tɛkˈnɑlədʒi ˈɛndʒəˈnɪɹɪŋ ˌɪnˈvɛnʃənz. ˌklæsəfəˈkeɪʃən: ɫcc* qthɹee* ˈhənəɹd thiɹty-fouɹ*. ˈsɛvən ebook* ɫcc* qthɹee* ˈhənəɹd thiɹty-fouɹ*.\n",
      " length:139\n",
      " length:132\n",
      "ˈsɛvən tfoɹty-fouɹ* tˈwɛnti ˈsɛvənˈtin pɹɪnt ddc* sɪks. θɹi ˈhənəɹd one--dctwenty-thɹee* ɫc* ˈɹɛkəɹd əˈveɪləbəɫ æt https://ɫccn*.\n",
      " length:129\n",
      " length:121\n",
      "loc*. gov/two* ˈbɪljən, ˈsɛvənˈtin ˈmɪljən, sɪks ˈθaʊzənd, tu ˈhənəɹd foɹty-eight* ebook* isbn* naɪn ˈtɹɪljən, ˈsɛvən ˈhənəɹd eighty-one* ˈbɪljən, wən ˈhənəɹd wən ˈmɪljən, naɪn ˈhənəɹd foɹty-six* ˈθaʊzənd, sɪks ˈhənəɹd tu ˈkəvəɹ ɑɹt baɪ suvadip* dɑs; mæn beɪst ɔn netfaɫls* ˈɹɛmi musseɹ/shutteɹstock* ˈkəvəɹ dɪˈzaɪn baɪ dʒɑn ˈvɔɹhiz vfouɹ*.\n",
      " length:340\n",
      " length:335\n",
      "wən ep* ˈkɑntɛnts ˈkəvəɹ ˈɔlsoʊ baɪ mæks tegmaɹk* ˈtaɪtəɫ peɪdʒ ˈkɑpiˌɹaɪt ˌdɛdəˈkeɪʃən acknowledgments* ˈpɹeɪˌlud: ðə teɪɫ əv ðə oʊˈmɛgə tim wən ˈwɛlkəm tɪ ðə moʊst ˌɪmˈpɔɹtənt ˌkɑnvəɹˈseɪʃən əv ɑɹ taɪm ə bɹif ˈhɪstəɹi əv kəmˈplɛksɪti ðə θɹi ˈsteɪdʒɪz əv laɪf ˈkɑntɹəˌvəɹsiz mɪskənˈsɛpʃənz ðə ɹoʊd.\n",
      " length:299\n",
      " length:297\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Generate cloned speech for each chunk\n",
    "if os.path.exists('processed'):\n",
    "    subprocess.run(['rmdir', '/S', '/Q', 'processed'], shell=True)\n",
    "\n",
    "# Extract source and target speaker embeddings\n",
    "source_se = torch.load('checkpoints/base_speakers/EN/en_default_se.pth', map_location=device)\n",
    "target_se, _ = se_extractor.get_se(reference_audio, tone_color_converter, target_dir='processed', vad=True)\n",
    "\n",
    "# Generate audio for each chunk\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for i, chunk in enumerate(text_chunks):\n",
    "    src_path = f'{output_dir}\\\\tmp_{i}.wav'\n",
    "    base_speaker_tts.tts(chunk, src_path, speaker='default', language='English', speed=1.0)\n",
    "    save_path = f'{output_dir}\\\\part_{i}.wav'\n",
    "    tone_color_converter.convert(\n",
    "        audio_src_path=src_path,\n",
    "        src_se=source_se,\n",
    "        tgt_se=target_se,\n",
    "        output_path=save_path,\n",
    "        message='@MyShell'\n",
    "    )\n",
    "    print(f'Generated audio for chunk {i+1}/{len(text_chunks)}: {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9411d5c6-9189-46e3-95db-dd57211cffaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\chunks\\\\part_0.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m combined \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mempty()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(text_chunks)):\n\u001b[1;32m----> 4\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mpart_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     combined \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m audio\n\u001b[0;32m      7\u001b[0m combined\u001b[38;5;241m.\u001b[39mexport(output_file, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmp3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py:808\u001b[0m, in \u001b[0;36mAudioSegment.from_wav\u001b[1;34m(cls, file, parameters)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_wav\u001b[39m(\u001b[38;5;28mcls\u001b[39m, file, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m file, close_file \u001b[38;5;241m=\u001b[39m \u001b[43m_fd_or_path_or_tempfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m:\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[1;34m(fd, mode, tempfile)\u001b[0m\n\u001b[0;32m     57\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[1;32m---> 60\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\chunks\\\\part_0.wav'"
     ]
    }
   ],
   "source": [
    "# Step 7: Merge audio chunks and save to D drive\n",
    "combined = AudioSegment.empty()\n",
    "for i in range(len(text_chunks)):\n",
    "    audio = AudioSegment.from_wav(f'{output_dir}\\\\part_{i}.wav')\n",
    "    combined += audio\n",
    "\n",
    "combined.export(output_file, format='mp3')\n",
    "print(f'Audiobook generated and saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ef6a0-becc-4343-a39b-10829c45d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Upload to Google Drive\n",
    "print(\"Authenticating with Google Drive...\")\n",
    "flow = InstalledAppFlow.from_client_secrets_file(\n",
    "    credentials_file,\n",
    "    scopes=['https://www.googleapis.com/auth/drive.file']\n",
    ")\n",
    "creds = flow.run_local_server(port=0)\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "file_metadata = {\n",
    "    'name': 'Life_3.0_audiobook.mp3',\n",
    "    'parents': [drive_folder_id]\n",
    "}\n",
    "media = MediaFileUpload(output_file, mimetype='audio/mpeg')\n",
    "file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "print(f'File uploaded to Google Drive with ID: {file.get(\"id\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823b2ad-27f6-4624-89ba-259d684a949d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
