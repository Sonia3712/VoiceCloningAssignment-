{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA86K0qQILry"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf2IT9R0csVc",
        "outputId": "1f02464b-d351-43ce-b8f3-1c227f1d98b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uv\n",
            "  Downloading uv-0.8.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.8.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.8.14\n",
            "Cloning into 'Zonos'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 340 (delta 159), reused 116 (delta 116), pack-reused 144 (from 1)\u001b[K\n",
            "Receiving objects: 100% (340/340), 3.03 MiB | 6.86 MiB/s, done.\n",
            "Resolving deltas: 100% (211/211), done.\n",
            "/content/Zonos/Zonos\n",
            "Using CPython 3.12.11 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[2mResolved \u001b[1m116 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m110 packages\u001b[0m \u001b[2min 1m 32s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m110 packages\u001b[0m \u001b[2min 712ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages without build isolation\u001b[0m \u001b[2min 33.73s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==23.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbabel\u001b[0m\u001b[2m==2.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcausal-conv1d\u001b[0m\u001b[2m==1.5.0.post8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.1.31\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.1.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclldutils\u001b[0m\u001b[2m==3.21.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcsvw\u001b[0m\u001b[2m==3.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdlinfo\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1meinops\u001b[0m\u001b[2m==0.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.115.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mffmpy\u001b[0m\u001b[2m==0.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflash-attn\u001b[0m\u001b[2m==2.7.4.post1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.15.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1minflect\u001b[0m\u001b[2m==7.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1misodate\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjsonschema-specifications\u001b[0m\u001b[2m==2024.10.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkanjize\u001b[0m\u001b[2m==1.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlanguage-tags\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlxml\u001b[0m\u001b[2m==5.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmamba-ssm\u001b[0m\u001b[2m==2.2.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown\u001b[0m\u001b[2m==3.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmore-itertools\u001b[0m\u001b[2m==10.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mninja\u001b[0m\u001b[2m==1.11.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.10.15\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mphonemizer\u001b[0m\u001b[2m==3.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.10.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.27.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydub\u001b[0m\u001b[2m==0.25.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpylatexenc\u001b[0m\u001b[2m==2.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrdflib\u001b[0m\u001b[2m==7.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mreferencing\u001b[0m\u001b[2m==0.36.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrfc3986\u001b[0m\u001b[2m==1.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==13.9.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrpds-py\u001b[0m\u001b[2m==0.22.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.9.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msafehttpx\u001b[0m\u001b[2m==0.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msegments\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msemantic-version\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==75.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoundfile\u001b[0m\u001b[2m==0.13.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.45.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msudachidict-full\u001b[0m\u001b[2m==20250129\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msudachipy\u001b[0m\u001b[2m==0.6.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtabulate\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.48.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtypeguard\u001b[0m\u001b[2m==4.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.15.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.12.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muritemplate\u001b[0m\u001b[2m==4.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==14.2\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak-ng espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 4,526 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpcaudio0 amd64 1.1-6build2 [8,956 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 espeak-ng-data amd64 1.50+dfsg-10ubuntu0.1 [3,956 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libespeak-ng1 amd64 1.50+dfsg-10ubuntu0.1 [207 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 espeak-ng amd64 1.50+dfsg-10ubuntu0.1 [343 kB]\n",
            "Fetched 4,526 kB in 1s (5,528 kB/s)\n",
            "Selecting previously unselected package libpcaudio0:amd64.\n",
            "(Reading database ... 126371 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcaudio0_1.1-6build2_amd64.deb ...\n",
            "Unpacking libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Selecting previously unselected package espeak-ng-data:amd64.\n",
            "Preparing to unpack .../espeak-ng-data_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package libespeak-ng1:amd64.\n",
            "Preparing to unpack .../libespeak-ng1_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package espeak-ng.\n",
            "Preparing to unpack .../espeak-ng_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Setting up espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Collecting deepgram-sdk\n",
            "  Downloading deepgram_sdk-4.8.1-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from deepgram-sdk) (0.28.1)\n",
            "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.12/dist-packages (from deepgram-sdk) (15.0.1)\n",
            "Collecting dataclasses-json>=0.6.3 (from deepgram-sdk)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from deepgram-sdk) (4.15.0)\n",
            "Requirement already satisfied: aiohttp>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from deepgram-sdk) (3.12.15)\n",
            "Requirement already satisfied: aiofiles>=23.2.1 in /usr/local/lib/python3.12/dist-packages (from deepgram-sdk) (24.1.0)\n",
            "Collecting aenum>=3.1.0 (from deepgram-sdk)\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting deprecation>=2.1.0 (from deepgram-sdk)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.1->deepgram-sdk) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json>=0.6.3->deepgram-sdk)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json>=0.6.3->deepgram-sdk)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from deprecation>=2.1.0->deepgram-sdk) (25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->deepgram-sdk) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->deepgram-sdk) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->deepgram-sdk) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->deepgram-sdk) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->deepgram-sdk) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.6.3->deepgram-sdk)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->deepgram-sdk) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepgram_sdk-4.8.1-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.9/157.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: aenum, pypdfium2, mypy-extensions, marshmallow, deprecation, typing-inspect, pdfminer.six, dataclasses-json, pdfplumber, deepgram-sdk\n",
            "Successfully installed aenum-3.1.16 dataclasses-json-0.6.7 deepgram-sdk-4.8.1 deprecation-2.1.0 marshmallow-3.26.1 mypy-extensions-1.1.0 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0 typing-inspect-0.9.0\n",
            "Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# Install essentials\n",
        "!pip install -U uv\n",
        "!git clone https://github.com/Zyphra/Zonos.git\n",
        "%cd Zonos\n",
        "!uv sync --extra compile  # For hybrid model compilation\n",
        "!apt install -y espeak-ng  # For phonemization\n",
        "!pip install pdfplumber pydub deepgram-sdk torchaudio torch\n",
        "print(\"Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJikwYG8KHSc",
        "outputId": "183c92a6-57f9-4c63-d430-52f8a7036f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "N6zEkcFIcsxZ",
        "outputId": "4e499880-93f2-45ea-e9d5-28827185a734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload your 'Life 3.0' PDF and your voice sample (.wav recommended):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-30ddb92c-94e6-46be-b0bb-e8d049db381f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-30ddb92c-94e6-46be-b0bb-e8d049db381f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving myvoice.mp3 to myvoice (1).mp3\n",
            "Saving max-tegmark-life-30-being-human-in-the-age-of-artificial-intelligence-alfred-a-knopf-2017-aTvn.pdf to max-tegmark-life-30-being-human-in-the-age-of-artificial-intelligence-alfred-a-knopf-2017-aTvn (1).pdf\n",
            "PDF: max-tegmark-life-30-being-human-in-the-age-of-artificial-intelligence-alfred-a-knopf-2017-aTvn (1).pdf, Voice: myvoice (1).mp3\n",
            "PDF: max-tegmark-life-30-being-human-in-the-age-of-artificial-intelligence-alfred-a-knopf-2017-aTvn (1).pdf, Voice: myvoice (1).mp3\n",
            "'myvoice (1).mp3' exists and is ready for use.\n"
          ]
        }
      ],
      "source": [
        "# Upload PDF and voice sample\n",
        "print(\"Upload your 'Life 3.0' PDF and your voice sample (.wav recommended):\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = next((k for k in uploaded if '.pdf' in k), 'life_3_0.pdf')\n",
        "voice_path = next((k for k in uploaded if k.endswith(('.wav', '.mp3'))), 'my_voice.wav')\n",
        "print(f\"PDF: {pdf_path}, Voice: {voice_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check if voice_path is defined and exists as a file\n",
        "print(f\"PDF: {pdf_path}, Voice: {voice_path}\")\n",
        "if voice_path and os.path.exists(voice_path):\n",
        "    print(f\"'{voice_path}' exists and is ready for use.\")\n",
        "else:\n",
        "    print(f\"'{voice_path}' does not exist or is not defined. Please re-upload a .wav or .mp3 file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-83V4wtctAn",
        "outputId": "ceb44c4a-1a25-4f18-89c6-e9f4ccf4cae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Deepgram API Key: 6b287043571893a4c9c0cacd166076e47d319e89\n",
            "API key entered.\n"
          ]
        }
      ],
      "source": [
        "# Enter Deepgram API Key\n",
        "DEEPGRAM_API_KEY = input(\"Enter your Deepgram API Key: \")\n",
        "print(\"API key entered.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyTtYejCKdOG",
        "outputId": "046aa211-cd52-4740-a0d0-2a59239d2a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 735382 characters from book.\n"
          ]
        }
      ],
      "source": [
        "import pdfplumber\n",
        "\n",
        "page_range = None  # Example: '1-10', or None for full book\n",
        "\n",
        "def extract_text(pdf_path, page_range=None):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        start, end = 0, len(pdf.pages)\n",
        "        if page_range:\n",
        "            s, e = page_range.split('-')\n",
        "            start, end = int(s) - 1, int(e)\n",
        "        for page in pdf.pages[start:end]:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "book_text = extract_text(pdf_path, page_range)\n",
        "print(f\"Extracted {len(book_text)} characters from book.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUhBwEiiKrcX",
        "outputId": "6c90bd77-98c7-4caf-e00a-6965410141ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing chunk 1/368...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-53451939.py:15: UnsupportedWarning: v is unsupported as of 4.0.0. deepgram.speak.v1 is deprecated. Use deepgram.speak.rest or deepgram.speak.websocket instead.\n",
            "  response = deepgram.speak.v(\"1\").stream_memory({\"text\": chunk}, options)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing chunk 2/368...\n",
            "Processing chunk 3/368...\n",
            "Processing chunk 4/368...\n",
            "Processing chunk 5/368...\n",
            "Processing chunk 6/368...\n",
            "Processing chunk 7/368...\n",
            "Processing chunk 8/368...\n",
            "Processing chunk 9/368...\n",
            "Processing chunk 10/368...\n",
            "Processing chunk 11/368...\n",
            "Processing chunk 12/368...\n",
            "Processing chunk 13/368...\n",
            "Processing chunk 14/368...\n",
            "Processing chunk 15/368...\n",
            "Processing chunk 16/368...\n",
            "Processing chunk 17/368...\n",
            "Processing chunk 18/368...\n",
            "Processing chunk 19/368...\n",
            "Processing chunk 20/368...\n",
            "Processing chunk 21/368...\n",
            "Processing chunk 22/368...\n",
            "Processing chunk 23/368...\n",
            "Processing chunk 24/368...\n",
            "Processing chunk 25/368...\n",
            "Processing chunk 26/368...\n",
            "Processing chunk 27/368...\n",
            "Processing chunk 28/368...\n",
            "Processing chunk 29/368...\n",
            "Processing chunk 30/368...\n",
            "Processing chunk 31/368...\n",
            "Processing chunk 32/368...\n",
            "Processing chunk 33/368...\n",
            "Processing chunk 34/368...\n",
            "Processing chunk 35/368...\n",
            "Processing chunk 36/368...\n",
            "Processing chunk 37/368...\n",
            "Processing chunk 38/368...\n",
            "Processing chunk 39/368...\n",
            "Processing chunk 40/368...\n",
            "Processing chunk 41/368...\n",
            "Processing chunk 42/368...\n",
            "Processing chunk 43/368...\n",
            "Processing chunk 44/368...\n",
            "Processing chunk 45/368...\n",
            "Processing chunk 46/368...\n",
            "Processing chunk 47/368...\n",
            "Processing chunk 48/368...\n",
            "Processing chunk 49/368...\n",
            "Processing chunk 50/368...\n",
            "Processing chunk 51/368...\n",
            "Processing chunk 52/368...\n",
            "Processing chunk 53/368...\n",
            "Processing chunk 54/368...\n",
            "Processing chunk 55/368...\n",
            "Processing chunk 56/368...\n",
            "Processing chunk 57/368...\n",
            "Processing chunk 58/368...\n",
            "Processing chunk 59/368...\n",
            "Processing chunk 60/368...\n",
            "Processing chunk 61/368...\n",
            "Processing chunk 62/368...\n",
            "Processing chunk 63/368...\n",
            "Processing chunk 64/368...\n",
            "Processing chunk 65/368...\n",
            "Processing chunk 66/368...\n",
            "Processing chunk 67/368...\n",
            "Processing chunk 68/368...\n",
            "Processing chunk 69/368...\n",
            "Processing chunk 70/368...\n",
            "Processing chunk 71/368...\n",
            "Processing chunk 72/368...\n",
            "Processing chunk 73/368...\n",
            "Processing chunk 74/368...\n",
            "Processing chunk 75/368...\n",
            "Processing chunk 76/368...\n",
            "Processing chunk 77/368...\n",
            "Processing chunk 78/368...\n",
            "Processing chunk 79/368...\n",
            "Processing chunk 80/368...\n",
            "Processing chunk 81/368...\n",
            "Processing chunk 82/368...\n",
            "Processing chunk 83/368...\n",
            "Processing chunk 84/368...\n",
            "Processing chunk 85/368...\n",
            "Processing chunk 86/368...\n",
            "Processing chunk 87/368...\n",
            "Processing chunk 88/368...\n",
            "Processing chunk 89/368...\n",
            "Processing chunk 90/368...\n",
            "Processing chunk 91/368...\n",
            "Processing chunk 92/368...\n",
            "Processing chunk 93/368...\n",
            "Processing chunk 94/368...\n",
            "Processing chunk 95/368...\n",
            "Processing chunk 96/368...\n",
            "Processing chunk 97/368...\n",
            "Processing chunk 98/368...\n",
            "Processing chunk 99/368...\n",
            "Processing chunk 100/368...\n",
            "Processing chunk 101/368...\n",
            "Processing chunk 102/368...\n",
            "Processing chunk 103/368...\n",
            "Processing chunk 104/368...\n",
            "Processing chunk 105/368...\n",
            "Processing chunk 106/368...\n",
            "Processing chunk 107/368...\n",
            "Processing chunk 108/368...\n",
            "Processing chunk 109/368...\n",
            "Processing chunk 110/368...\n",
            "Processing chunk 111/368...\n",
            "Processing chunk 112/368...\n",
            "Processing chunk 113/368...\n",
            "Processing chunk 114/368...\n",
            "Processing chunk 115/368...\n",
            "Processing chunk 116/368...\n",
            "Processing chunk 117/368...\n",
            "Processing chunk 118/368...\n",
            "Processing chunk 119/368...\n",
            "Processing chunk 120/368...\n",
            "Processing chunk 121/368...\n",
            "Processing chunk 122/368...\n",
            "Processing chunk 123/368...\n",
            "Processing chunk 124/368...\n",
            "Processing chunk 125/368...\n",
            "Processing chunk 126/368...\n",
            "Processing chunk 127/368...\n",
            "Processing chunk 128/368...\n",
            "Processing chunk 129/368...\n",
            "Processing chunk 130/368...\n",
            "Processing chunk 131/368...\n",
            "Processing chunk 132/368...\n",
            "Processing chunk 133/368...\n",
            "Processing chunk 134/368...\n",
            "Processing chunk 135/368...\n",
            "Processing chunk 136/368...\n",
            "Processing chunk 137/368...\n",
            "Processing chunk 138/368...\n",
            "Processing chunk 139/368...\n",
            "Processing chunk 140/368...\n",
            "Processing chunk 141/368...\n",
            "Processing chunk 142/368...\n",
            "Processing chunk 143/368...\n",
            "Processing chunk 144/368...\n",
            "Processing chunk 145/368...\n",
            "Processing chunk 146/368...\n",
            "Processing chunk 147/368...\n",
            "Processing chunk 148/368...\n",
            "Processing chunk 149/368...\n",
            "Processing chunk 150/368...\n",
            "Processing chunk 151/368...\n",
            "Processing chunk 152/368...\n",
            "Processing chunk 153/368...\n",
            "Processing chunk 154/368...\n",
            "Processing chunk 155/368...\n",
            "Processing chunk 156/368...\n",
            "Processing chunk 157/368...\n",
            "Processing chunk 158/368...\n",
            "Processing chunk 159/368...\n",
            "Processing chunk 160/368...\n",
            "Processing chunk 161/368...\n",
            "Processing chunk 162/368...\n",
            "Processing chunk 163/368...\n",
            "Processing chunk 164/368...\n",
            "Processing chunk 165/368...\n",
            "Processing chunk 166/368...\n",
            "Processing chunk 167/368...\n",
            "Processing chunk 168/368...\n",
            "Processing chunk 169/368...\n",
            "Processing chunk 170/368...\n",
            "Processing chunk 171/368...\n",
            "Processing chunk 172/368...\n",
            "Processing chunk 173/368...\n",
            "Processing chunk 174/368...\n",
            "Processing chunk 175/368...\n",
            "Processing chunk 176/368...\n",
            "Processing chunk 177/368...\n",
            "Processing chunk 178/368...\n",
            "Processing chunk 179/368...\n",
            "Processing chunk 180/368...\n",
            "Processing chunk 181/368...\n",
            "Processing chunk 182/368...\n",
            "Processing chunk 183/368...\n",
            "Processing chunk 184/368...\n",
            "Processing chunk 185/368...\n",
            "Processing chunk 186/368...\n",
            "Processing chunk 187/368...\n",
            "Processing chunk 188/368...\n",
            "Processing chunk 189/368...\n",
            "Processing chunk 190/368...\n",
            "Processing chunk 191/368...\n",
            "Processing chunk 192/368...\n",
            "Processing chunk 193/368...\n",
            "Processing chunk 194/368...\n",
            "Processing chunk 195/368...\n",
            "Processing chunk 196/368...\n",
            "Processing chunk 197/368...\n",
            "Processing chunk 198/368...\n",
            "Processing chunk 199/368...\n",
            "Processing chunk 200/368...\n",
            "Processing chunk 201/368...\n",
            "Processing chunk 202/368...\n",
            "Processing chunk 203/368...\n",
            "Processing chunk 204/368...\n",
            "Processing chunk 205/368...\n",
            "Processing chunk 206/368...\n",
            "Processing chunk 207/368...\n",
            "Processing chunk 208/368...\n",
            "Processing chunk 209/368...\n",
            "Processing chunk 210/368...\n",
            "Processing chunk 211/368...\n",
            "Processing chunk 212/368...\n",
            "Processing chunk 213/368...\n",
            "Processing chunk 214/368...\n",
            "Processing chunk 215/368...\n",
            "Processing chunk 216/368...\n",
            "Processing chunk 217/368...\n",
            "Processing chunk 218/368...\n",
            "Processing chunk 219/368...\n",
            "Processing chunk 220/368...\n",
            "Processing chunk 221/368...\n",
            "Processing chunk 222/368...\n",
            "Processing chunk 223/368...\n",
            "Processing chunk 224/368...\n",
            "Processing chunk 225/368...\n",
            "Processing chunk 226/368...\n",
            "Processing chunk 227/368...\n",
            "Processing chunk 228/368...\n",
            "Processing chunk 229/368...\n",
            "Processing chunk 230/368...\n",
            "Processing chunk 231/368...\n",
            "Processing chunk 232/368...\n",
            "Processing chunk 233/368...\n",
            "Processing chunk 234/368...\n",
            "Processing chunk 235/368...\n",
            "Processing chunk 236/368...\n",
            "Processing chunk 237/368...\n",
            "Processing chunk 238/368...\n",
            "Processing chunk 239/368...\n",
            "Processing chunk 240/368...\n",
            "Processing chunk 241/368...\n",
            "Processing chunk 242/368...\n",
            "Processing chunk 243/368...\n",
            "Processing chunk 244/368...\n",
            "Processing chunk 245/368...\n",
            "Processing chunk 246/368...\n",
            "Processing chunk 247/368...\n",
            "Processing chunk 248/368...\n",
            "Processing chunk 249/368...\n",
            "Processing chunk 250/368...\n",
            "Processing chunk 251/368...\n",
            "Processing chunk 252/368...\n",
            "Processing chunk 253/368...\n",
            "Processing chunk 254/368...\n",
            "Processing chunk 255/368...\n",
            "Processing chunk 256/368...\n",
            "Processing chunk 257/368...\n",
            "Processing chunk 258/368...\n",
            "Processing chunk 259/368...\n",
            "Processing chunk 260/368...\n",
            "Processing chunk 261/368...\n",
            "Processing chunk 262/368...\n",
            "Processing chunk 263/368...\n",
            "Processing chunk 264/368...\n",
            "Processing chunk 265/368...\n",
            "Processing chunk 266/368...\n",
            "Processing chunk 267/368...\n",
            "Processing chunk 268/368...\n",
            "Processing chunk 269/368...\n",
            "Processing chunk 270/368...\n",
            "Processing chunk 271/368...\n",
            "Processing chunk 272/368...\n",
            "Processing chunk 273/368...\n",
            "Processing chunk 274/368...\n",
            "Processing chunk 275/368...\n",
            "Processing chunk 276/368...\n",
            "Processing chunk 277/368...\n",
            "Processing chunk 278/368...\n",
            "Processing chunk 279/368...\n",
            "Processing chunk 280/368...\n",
            "Processing chunk 281/368...\n",
            "Processing chunk 282/368...\n",
            "Processing chunk 283/368...\n",
            "Processing chunk 284/368...\n",
            "Processing chunk 285/368...\n",
            "Processing chunk 286/368...\n",
            "Processing chunk 287/368...\n",
            "Processing chunk 288/368...\n",
            "Processing chunk 289/368...\n",
            "Processing chunk 290/368...\n",
            "Processing chunk 291/368...\n",
            "Processing chunk 292/368...\n",
            "Processing chunk 293/368...\n",
            "Processing chunk 294/368...\n",
            "Processing chunk 295/368...\n",
            "Processing chunk 296/368...\n",
            "Processing chunk 297/368...\n",
            "Processing chunk 298/368...\n",
            "Processing chunk 299/368...\n",
            "Processing chunk 300/368...\n",
            "Processing chunk 301/368...\n",
            "Processing chunk 302/368...\n",
            "Processing chunk 303/368...\n",
            "Processing chunk 304/368...\n",
            "Processing chunk 305/368...\n",
            "Processing chunk 306/368...\n",
            "Processing chunk 307/368...\n",
            "Processing chunk 308/368...\n",
            "Processing chunk 309/368...\n",
            "Processing chunk 310/368...\n",
            "Processing chunk 311/368...\n",
            "Processing chunk 312/368...\n",
            "Processing chunk 313/368...\n",
            "Processing chunk 314/368...\n",
            "Processing chunk 315/368...\n",
            "Processing chunk 316/368...\n",
            "Processing chunk 317/368...\n",
            "Processing chunk 318/368...\n",
            "Processing chunk 319/368...\n",
            "Processing chunk 320/368...\n",
            "Processing chunk 321/368...\n",
            "Processing chunk 322/368...\n",
            "Processing chunk 323/368...\n",
            "Processing chunk 324/368...\n",
            "Processing chunk 325/368...\n",
            "Processing chunk 326/368...\n",
            "Processing chunk 327/368...\n",
            "Processing chunk 328/368...\n",
            "Processing chunk 329/368...\n",
            "Processing chunk 330/368...\n",
            "Processing chunk 331/368...\n",
            "Processing chunk 332/368...\n",
            "Processing chunk 333/368...\n",
            "Processing chunk 334/368...\n",
            "Processing chunk 335/368...\n",
            "Processing chunk 336/368...\n",
            "Processing chunk 337/368...\n",
            "Processing chunk 338/368...\n",
            "Processing chunk 339/368...\n",
            "Processing chunk 340/368...\n",
            "Processing chunk 341/368...\n",
            "Processing chunk 342/368...\n",
            "Processing chunk 343/368...\n",
            "Processing chunk 344/368...\n",
            "Processing chunk 345/368...\n",
            "Processing chunk 346/368...\n",
            "Processing chunk 347/368...\n",
            "Processing chunk 348/368...\n",
            "Processing chunk 349/368...\n",
            "Processing chunk 350/368...\n",
            "Processing chunk 351/368...\n",
            "Processing chunk 352/368...\n",
            "Processing chunk 353/368...\n",
            "Processing chunk 354/368...\n",
            "Processing chunk 355/368...\n",
            "Processing chunk 356/368...\n",
            "Processing chunk 357/368...\n",
            "Processing chunk 358/368...\n",
            "Processing chunk 359/368...\n",
            "Processing chunk 360/368...\n",
            "Processing chunk 361/368...\n",
            "Processing chunk 362/368...\n",
            "Processing chunk 363/368...\n",
            "Processing chunk 364/368...\n",
            "Processing chunk 365/368...\n",
            "Processing chunk 366/368...\n",
            "Processing chunk 367/368...\n",
            "Processing chunk 368/368...\n",
            "✅ Deepgram TTS saved to: /content/drive/My Drive/life_30_deepgram_tts.wav\n"
          ]
        }
      ],
      "source": [
        "from deepgram import DeepgramClient, SpeakOptions\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "deepgram = DeepgramClient(DEEPGRAM_API_KEY)\n",
        "\n",
        "# Split into chunks for Deepgram\n",
        "chunks = [book_text[i:i+2000] for i in range(0, len(book_text), 2000)]\n",
        "deepgram_chunks = []\n",
        "\n",
        "for idx, chunk in enumerate(chunks):\n",
        "    print(f\"Processing chunk {idx+1}/{len(chunks)}...\")\n",
        "\n",
        "    options = SpeakOptions(model=\"aura-asteria-en\", encoding=\"linear16\", container=\"wav\")\n",
        "    response = deepgram.speak.v(\"1\").stream_memory({\"text\": chunk}, options)\n",
        "\n",
        "    temp_path = f\"deepgram_chunk_{idx}.wav\"\n",
        "    with open(temp_path, \"wb\") as f:\n",
        "        f.write(response.stream.read())   # save temp wav\n",
        "\n",
        "    deepgram_chunks.append(temp_path)\n",
        "\n",
        "# Merge into one wav\n",
        "combined_deepgram = AudioSegment.empty()\n",
        "for path in deepgram_chunks:\n",
        "    combined_deepgram += AudioSegment.from_wav(path)\n",
        "    os.remove(path)  # cleanup temp files\n",
        "\n",
        "deepgram_wav = \"/content/drive/My Drive/life_30_deepgram_tts.wav\"\n",
        "combined_deepgram.export(deepgram_wav, format=\"wav\")\n",
        "print(f\"✅ Deepgram TTS saved to: {deepgram_wav}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DdoIoRTmEQIy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}